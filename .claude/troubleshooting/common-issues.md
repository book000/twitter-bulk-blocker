# ã‚ˆãã‚ã‚‹å•é¡Œã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

## èªè¨¼é–¢é€£ã®å•é¡Œ

### ğŸš¨ å•é¡Œ: 401 Unauthorized ã‚¨ãƒ©ãƒ¼
```
ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: "èªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ (401)"
```

**åŸå› ã¨å¯¾å‡¦æ³•:**
1. **ã‚¯ãƒƒã‚­ãƒ¼ã®æœ‰åŠ¹æœŸé™åˆ‡ã‚Œ**
   ```python
   # ç¢ºèªæ–¹æ³•
   cookies = self.cookie_manager.load_cookies()
   if not cookies or 'ct0' not in cookies or 'auth_token' not in cookies:
       print("âŒ å¿…é ˆã‚¯ãƒƒã‚­ãƒ¼ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
   
   # å¯¾å‡¦æ³•
   # 1. ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰æœ€æ–°ã®ã‚¯ãƒƒã‚­ãƒ¼ã‚’å–å¾—
   # 2. cookies.jsonãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
   ```

2. **CSRFãƒˆãƒ¼ã‚¯ãƒ³ã®ä¸æ•´åˆ**
   ```python
   # ç¢ºèªæ–¹æ³•
   def check_csrf_token():
       cookies = self.cookie_manager.load_cookies()
       ct0_cookie = cookies.get('ct0')
       
       # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼ã®CSRFãƒˆãƒ¼ã‚¯ãƒ³ã¨æ¯”è¼ƒ
       headers = self.get_headers()
       csrf_header = headers.get('x-csrf-token')
       
       if ct0_cookie != csrf_header:
           print("âŒ CSRFãƒˆãƒ¼ã‚¯ãƒ³ãŒä¸æ•´åˆã§ã™")
           return False
       return True
   
   # å¯¾å‡¦æ³•
   self.cookie_manager.clear_cache()
   # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§å†å®Ÿè¡Œ
   ```

3. **ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåˆ¶é™ãƒ»å‡çµ**
   ```python
   # ç¢ºèªæ–¹æ³•
   # æ‰‹å‹•ã§Twitterã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦çŠ¶æ…‹ç¢ºèª
   # - ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒå‡çµã•ã‚Œã¦ã„ãªã„ã‹ï¼Ÿ
   # - äºŒæ®µéšèªè¨¼ãŒè¦æ±‚ã•ã‚Œã¦ã„ãªã„ã‹ï¼Ÿ
   # - ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ­ãƒƒã‚¯ã•ã‚Œã¦ã„ãªã„ã‹ï¼Ÿ
   ```

### ğŸš¨ å•é¡Œ: "ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ãƒ•ãƒ©ã‚°ãŒç„¡åŠ¹" ã‚¨ãƒ©ãƒ¼
```
ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: "å¿…è¦ãªãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ãƒ•ãƒ©ã‚°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
```

**åŸå› ã¨å¯¾å‡¦æ³•:**
```python
# æœ€æ–°ã®ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ãƒ•ãƒ©ã‚°ã«æ›´æ–°
FEATURES = {
    "hidden_profile_likes_enabled": True,
    "rweb_tipjar_consumption_enabled": True,
    "responsive_web_graphql_exclude_directive_enabled": True,
    "responsive_web_graphql_timeline_navigation_enabled": True,
    "responsive_web_graphql_skip_user_profile_image_extensions_enabled": False,
    # Twitterã®ä»•æ§˜å¤‰æ›´ã«ã‚ˆã‚Šå®šæœŸçš„ã«æ›´æ–°ãŒå¿…è¦
}

# ãƒ‡ãƒãƒƒã‚°æ–¹æ³•
def debug_feature_flags():
    # ãƒ–ãƒ©ã‚¦ã‚¶ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¿ãƒ–ã§Twitterã®å®Ÿéš›ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ç¢ºèª
    # æœ€æ–°ã®featuresãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒ¼
    pass
```

## APIé–¢é€£ã®å•é¡Œ

### ğŸš¨ å•é¡Œ: 429 Rate Limit ã‚¨ãƒ©ãƒ¼
```
ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: "Rate limit exceeded"
```

**åŸå› ã¨å¯¾å‡¦æ³•:**
```python
def handle_rate_limit_error(response):
    """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã®è©³ç´°è§£æã¨å¯¾å‡¦"""
    
    # 1. ãƒ¬ãƒ¼ãƒˆåˆ¶é™æƒ…å ±ã®å–å¾—
    remaining = response.headers.get('x-rate-limit-remaining', 0)
    reset_time = response.headers.get('x-rate-limit-reset', 0)
    
    print(f"ğŸ“Š ãƒ¬ãƒ¼ãƒˆåˆ¶é™çŠ¶æ³:")
    print(f"  æ®‹ã‚Šå›æ•°: {remaining}")
    print(f"  ãƒªã‚»ãƒƒãƒˆæ™‚åˆ»: {datetime.fromtimestamp(int(reset_time))}")
    
    # 2. é©åˆ‡ãªå¾…æ©Ÿæ™‚é–“ã®è¨ˆç®—
    wait_seconds = max(int(reset_time) - int(time.time()), 60)
    print(f"â° {wait_seconds}ç§’å¾…æ©Ÿã—ã¾ã™...")
    
    # 3. æ®µéšçš„ãªå†é–‹
    time.sleep(wait_seconds + 10)  # ä½™è£•ã‚’ã‚‚ã£ã¦å¾…æ©Ÿ
    return True

# äºˆé˜²ç­–
def implement_rate_limit_prevention():
    """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®äºˆé˜²ç­–"""
    
    # APIã‚³ãƒ¼ãƒ«æ•°ã®ã‚«ã‚¦ãƒ³ãƒˆ
    self.api_call_count = 0
    self.last_reset_time = time.time()
    
    def before_api_call(self):
        if self.api_call_count >= 140:  # åˆ¶é™ã®å°‘ã—æ‰‹å‰
            wait_time = 900 - (time.time() - self.last_reset_time)
            if wait_time > 0:
                print(f"ğŸ›¡ï¸ äºˆé˜²çš„å¾…æ©Ÿ: {wait_time}ç§’")
                time.sleep(wait_time)
            self.api_call_count = 0
            self.last_reset_time = time.time()
        
        self.api_call_count += 1
```

### ğŸš¨ å•é¡Œ: GraphQLã‚¨ãƒ©ãƒ¼ "User not found"
```
ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {"errors": [{"message": "User not found"}]}
```

**åŸå› ã¨å¯¾å‡¦æ³•:**
```python
def handle_user_not_found(screen_name, user_id=None):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼æœªç™ºè¦‹ã‚¨ãƒ©ãƒ¼ã®è©³ç´°åˆ†æ"""
    
    # 1. åŸå› ã®ç‰¹å®š
    possible_causes = [
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’å‰Šé™¤ã—ãŸ",
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼åãŒå¤‰æ›´ã•ã‚ŒãŸ", 
        "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒå‡çµã•ã‚ŒãŸ",
        "ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã‚¢ã‚«ã‚¦ãƒ³ãƒˆã§æ¤œç´¢ä¸å¯",
        "ä¸€æ™‚çš„ãªTwitterå´ã®å•é¡Œ"
    ]
    
    print(f"â“ {screen_name} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚è€ƒãˆã‚‰ã‚Œã‚‹åŸå› :")
    for i, cause in enumerate(possible_causes, 1):
        print(f"  {i}. {cause}")
    
    # 2. å¯¾å‡¦æ³•ã®å®Ÿè¡Œ
    # æ°¸ç¶šçš„å¤±æ•—ã¨ã—ã¦è¨˜éŒ²
    self.database.record_permanent_failure(
        screen_name=screen_name,
        user_id=user_id,
        error_type="not_found",
        error_message="ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
    )
    
    print(f"ğŸ“ {screen_name} ã‚’æ°¸ç¶šçš„å¤±æ•—ã¨ã—ã¦è¨˜éŒ²ã—ã¾ã—ãŸ")
    return {"status": "permanent_failure", "reason": "not_found"}
```

## ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹é–¢é€£ã®å•é¡Œ

### ğŸš¨ å•é¡Œ: SQLite database is locked
```
ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: "database is locked"
```

**åŸå› ã¨å¯¾å‡¦æ³•:**
```python
def fix_database_lock():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ­ãƒƒã‚¯å•é¡Œã®è§£æ±º"""
    
    # 1. åŸå› ã®ç¢ºèª
    causes = [
        "ä»–ã®ãƒ—ãƒ­ã‚»ã‚¹ãŒåŒã˜DBãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ä¸­",
        "å‰å›ã®å‡¦ç†ãŒç•°å¸¸çµ‚äº†ã—ã¦ãƒ­ãƒƒã‚¯ãŒæ®‹å­˜",
        "ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™å•é¡Œ", 
        "SQLiteæ¥ç¶šãŒé©åˆ‡ã«ã‚¯ãƒ­ãƒ¼ã‚ºã•ã‚Œã¦ã„ãªã„"
    ]
    
    # 2. è¨ºæ–­ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
    def diagnose_db_lock(db_file):
        import sqlite3
        import os
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
        if not os.path.exists(db_file):
            print(f"âŒ DBãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {db_file}")
            return False
        
        # ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ç¢ºèª
        if not os.access(db_file, os.R_OK | os.W_OK):
            print(f"âŒ DBãƒ•ã‚¡ã‚¤ãƒ«ã®æ¨©é™ãŒä¸è¶³: {db_file}")
            return False
        
        # ãƒ­ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
        lock_files = [f"{db_file}-wal", f"{db_file}-shm"]
        for lock_file in lock_files:
            if os.path.exists(lock_file):
                print(f"âš ï¸ ãƒ­ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {lock_file}")
        
        # æ¥ç¶šãƒ†ã‚¹ãƒˆ
        try:
            with sqlite3.connect(db_file, timeout=5) as conn:
                conn.execute("SELECT 1")
                print("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šæ­£å¸¸")
                return True
        except sqlite3.OperationalError as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    # 3. ä¿®å¾©å‡¦ç†
    def repair_database_lock(db_file):
        import os
        import time
        
        # WALãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ï¼ˆæ…é‡ã«ï¼‰
        wal_file = f"{db_file}-wal"
        shm_file = f"{db_file}-shm"
        
        if os.path.exists(wal_file):
            try:
                os.remove(wal_file)
                print(f"ğŸ—‘ï¸ WALãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤: {wal_file}")
            except OSError as e:
                print(f"âŒ WALãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å¤±æ•—: {e}")
        
        if os.path.exists(shm_file):
            try:
                os.remove(shm_file)
                print(f"ğŸ—‘ï¸ SHMãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤: {shm_file}")
            except OSError as e:
                print(f"âŒ SHMãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å¤±æ•—: {e}")
        
        # å°‘ã—å¾…æ©Ÿ
        time.sleep(1)
        
        # å†æ¥ç¶šãƒ†ã‚¹ãƒˆ
        return diagnose_db_lock(db_file)
```

### ğŸš¨ å•é¡Œ: é‡è¤‡ãƒ‡ãƒ¼ã‚¿ã®æŒ¿å…¥ã‚¨ãƒ©ãƒ¼
```
ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: "UNIQUE constraint failed"
```

**åŸå› ã¨å¯¾å‡¦æ³•:**
```python
def handle_duplicate_data():
    """é‡è¤‡ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ©ãƒ¼ã®å¯¾å‡¦"""
    
    # 1. UPSERTæ“ä½œã®ä½¿ç”¨
    def safe_insert_or_update(self, user_id, screen_name, status):
        query = """
        INSERT INTO block_history (user_id, screen_name, status, timestamp)
        VALUES (?, ?, ?, ?)
        ON CONFLICT(user_id, screen_name) DO UPDATE SET
            status = excluded.status,
            timestamp = excluded.timestamp
        """
        
        with sqlite3.connect(self.db_file) as conn:
            cursor = conn.cursor()
            cursor.execute(query, (user_id, screen_name, status, time.time()))
    
    # 2. äº‹å‰ãƒã‚§ãƒƒã‚¯
    def insert_with_check(self, user_id, screen_name, status):
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
        existing = self.get_user_history(user_id, screen_name)
        
        if existing:
            # æ›´æ–°
            self.update_user_status(user_id, screen_name, status)
            print(f"ğŸ”„ ãƒ‡ãƒ¼ã‚¿æ›´æ–°: {screen_name}")
        else:
            # æ–°è¦æŒ¿å…¥
            self.insert_new_user(user_id, screen_name, status)
            print(f"â• ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥: {screen_name}")
```

## ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é–¢é€£ã®å•é¡Œ

### ğŸš¨ å•é¡Œ: Connection timeout / Network error
```
ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: "requests.exceptions.ConnectionError"
```

**åŸå› ã¨å¯¾å‡¦æ³•:**
```python
def handle_network_issues():
    """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å•é¡Œã®è¨ºæ–­ã¨å¯¾å‡¦"""
    
    # 1. æ¥ç¶šè¨ºæ–­
    def diagnose_network():
        import socket
        import requests
        import time
        
        # DNSè§£æ±ºãƒ†ã‚¹ãƒˆ
        try:
            socket.gethostbyname('twitter.com')
            print("âœ… DNSè§£æ±ºæ­£å¸¸")
        except socket.gaierror:
            print("âŒ DNSè§£æ±ºå¤±æ•—")
            return False
        
        # HTTPæ¥ç¶šãƒ†ã‚¹ãƒˆ
        try:
            response = requests.get('https://twitter.com', timeout=10)
            print(f"âœ… HTTPæ¥ç¶šæ­£å¸¸ (ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status_code})")
        except requests.exceptions.RequestException as e:
            print(f"âŒ HTTPæ¥ç¶šå¤±æ•—: {e}")
            return False
        
        return True
    
    # 2. ãƒªãƒˆãƒ©ã‚¤æˆ¦ç•¥
    def network_retry_wrapper(func, *args, **kwargs):
        max_retries = 3
        base_delay = 30
        
        for attempt in range(max_retries):
            try:
                return func(*args, **kwargs)
            except requests.exceptions.ConnectionError as e:
                if attempt == max_retries - 1:
                    raise e
                
                delay = base_delay * (2 ** attempt)
                print(f"ğŸ”„ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ã€{delay}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ (è©¦è¡Œ: {attempt + 1}/{max_retries})")
                time.sleep(delay)
            except requests.exceptions.Timeout as e:
                print(f"â° ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç™ºç”Ÿ: {e}")
                if attempt == max_retries - 1:
                    raise e
                time.sleep(base_delay)
    
    # 3. ãƒ—ãƒ­ã‚­ã‚·ãƒ»VPNç¢ºèª
    def check_proxy_settings():
        import os
        
        proxy_vars = ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy']
        for var in proxy_vars:
            if os.environ.get(var):
                print(f"ğŸŒ ãƒ—ãƒ­ã‚­ã‚·è¨­å®šç™ºè¦‹: {var} = {os.environ[var]}")
                print("æ³¨æ„: ãƒ—ãƒ­ã‚­ã‚·è¨­å®šãŒTwitterã‚¢ã‚¯ã‚»ã‚¹ã«å½±éŸ¿ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
```

## ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»æ¨©é™é–¢é€£ã®å•é¡Œ

### ğŸš¨ å•é¡Œ: Permission denied / File access error
```
ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: "PermissionError: [Errno 13] Permission denied"
```

**åŸå› ã¨å¯¾å‡¦æ³•:**
```python
def handle_file_permission_issues():
    """ãƒ•ã‚¡ã‚¤ãƒ«æ¨©é™å•é¡Œã®è¨ºæ–­ã¨ä¿®å¾©"""
    
    # 1. æ¨©é™è¨ºæ–­
    def diagnose_file_permissions(file_path):
        import os
        import stat
        
        if not os.path.exists(file_path):
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {file_path}")
            return False
        
        # æ¨©é™æƒ…å ±ã®å–å¾—
        file_stat = os.stat(file_path)
        permissions = stat.filemode(file_stat.st_mode)
        owner = file_stat.st_uid
        group = file_stat.st_gid
        
        print(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±: {file_path}")
        print(f"  æ¨©é™: {permissions}")
        print(f"  æ‰€æœ‰è€…ID: {owner}")
        print(f"  ã‚°ãƒ«ãƒ¼ãƒ—ID: {group}")
        
        # èª­ã¿æ›¸ãæ¨©é™ã®ç¢ºèª
        readable = os.access(file_path, os.R_OK)
        writable = os.access(file_path, os.W_OK)
        
        print(f"  èª­ã¿å–ã‚Šå¯èƒ½: {readable}")
        print(f"  æ›¸ãè¾¼ã¿å¯èƒ½: {writable}")
        
        return readable and writable
    
    # 2. æ¨©é™ä¿®å¾©
    def fix_file_permissions(file_path):
        import os
        
        try:
            # èª­ã¿æ›¸ãæ¨©é™ã‚’ä»˜ä¸
            os.chmod(file_path, 0o600)  # æ‰€æœ‰è€…ã®ã¿èª­ã¿æ›¸ã
            print(f"âœ… æ¨©é™ä¿®å¾©å®Œäº†: {file_path}")
            return True
        except OSError as e:
            print(f"âŒ æ¨©é™ä¿®å¾©å¤±æ•—: {e}")
            return False
    
    # 3. ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    def ensure_directory_exists(dir_path):
        import os
        
        if not os.path.exists(dir_path):
            try:
                os.makedirs(dir_path, exist_ok=True)
                print(f"ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: {dir_path}")
            except OSError as e:
                print(f"âŒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆå¤±æ•—: {e}")
                return False
        
        return True
```

## ãƒ‡ãƒãƒƒã‚°ãƒ»è¨ºæ–­ãƒ„ãƒ¼ãƒ«

### ç·åˆè¨ºæ–­ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```python
def run_comprehensive_diagnosis():
    """å…¨ä½“çš„ãªè¨ºæ–­ã‚’å®Ÿè¡Œ"""
    
    print("ğŸ” Twitter Block Tool è¨ºæ–­é–‹å§‹")
    print("=" * 50)
    
    # 1. ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
    required_files = [
        'cookies.json',
        'users.json', 
        'block_history.db'
    ]
    
    print("\nğŸ“ å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª:")
    for file_path in required_files:
        if os.path.exists(file_path):
            size = os.path.getsize(file_path)
            print(f"  âœ… {file_path} (ã‚µã‚¤ã‚º: {size} bytes)")
        else:
            print(f"  âŒ {file_path} (è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“)")
    
    # 2. èªè¨¼çŠ¶æ…‹ç¢ºèª
    print("\nğŸ” èªè¨¼çŠ¶æ…‹ç¢ºèª:")
    try:
        cookies = load_cookies()
        if 'ct0' in cookies and 'auth_token' in cookies:
            print("  âœ… å¿…é ˆã‚¯ãƒƒã‚­ãƒ¼å­˜åœ¨")
        else:
            print("  âŒ å¿…é ˆã‚¯ãƒƒã‚­ãƒ¼ä¸è¶³")
    except Exception as e:
        print(f"  âŒ ã‚¯ãƒƒã‚­ãƒ¼èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    # 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç¢ºèª
    print("\nğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç¢ºèª:")
    try:
        with sqlite3.connect('block_history.db') as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM block_history")
            count = cursor.fetchone()[0]
            print(f"  âœ… ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {count}")
    except Exception as e:
        print(f"  âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
    
    # 4. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç¢ºèª
    print("\nğŸŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç¢ºèª:")
    try:
        response = requests.get('https://twitter.com', timeout=10)
        print(f"  âœ… Twitteræ¥ç¶šæ­£å¸¸ (ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status_code})")
    except Exception as e:
        print(f"  âŒ Twitteræ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
    
    print("\nâœ… è¨ºæ–­å®Œäº†")

# ä½¿ç”¨æ–¹æ³•
if __name__ == "__main__":
    run_comprehensive_diagnosis()
```

## ç·Šæ€¥æ™‚å¯¾å¿œ

### ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ»å¾©æ—§
```python
def emergency_backup():
    """ç·Šæ€¥æ™‚ã®ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
    import shutil
    import datetime
    
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_dir = f"backup_{timestamp}"
    
    os.makedirs(backup_dir, exist_ok=True)
    
    # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    important_files = [
        'block_history.db',
        'cookies.json',
        'users.json'
    ]
    
    for file_path in important_files:
        if os.path.exists(file_path):
            shutil.copy2(file_path, backup_dir)
            print(f"ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {file_path} â†’ {backup_dir}")
    
    print(f"âœ… ç·Šæ€¥ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: {backup_dir}")
    return backup_dir

def emergency_recovery(backup_dir):
    """ç·Šæ€¥æ™‚ã®å¾©æ—§å‡¦ç†"""
    if not os.path.exists(backup_dir):
        print(f"âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {backup_dir}")
        return False
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã®å¾©æ—§
    for file_name in os.listdir(backup_dir):
        src = os.path.join(backup_dir, file_name)
        dst = file_name
        
        try:
            shutil.copy2(src, dst)
            print(f"ğŸ”„ å¾©æ—§: {src} â†’ {dst}")
        except Exception as e:
            print(f"âŒ å¾©æ—§å¤±æ•—: {e}")
    
    print("âœ… ç·Šæ€¥å¾©æ—§å®Œäº†")
    return True
```