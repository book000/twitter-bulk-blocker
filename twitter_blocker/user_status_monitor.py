"""
ActiveçŠ¶æ…‹ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°å¤‰åŒ–ç›£è¦–æ©Ÿèƒ½
é•·æœŸç¨¼åƒæ™‚ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å¤‰åŒ–ã®è¿½è·¡ã¨403ã‚¨ãƒ©ãƒ¼äºˆæ¸¬
"""

import json
import sqlite3
import time
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Tuple

from .database import DatabaseManager


class UserStatusMonitor:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å¤‰åŒ–ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, database_manager: DatabaseManager):
        self.db = database_manager
        self.session_id = self._generate_session_id()
        self.init_monitoring_tables()
    
    def _generate_session_id(self) -> str:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ç”Ÿæˆ"""
        return f"status_{int(time.time())}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    def init_monitoring_tables(self):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç›£è¦–ç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ã®åˆæœŸåŒ–"""
        with sqlite3.connect(self.db.db_file) as conn:
            cursor = conn.cursor()
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS user_status_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp REAL NOT NULL,
                    session_id TEXT NOT NULL,
                    service_name TEXT NOT NULL,
                    total_users INTEGER NOT NULL,
                    blocked_users INTEGER NOT NULL,
                    failed_users INTEGER NOT NULL,
                    active_failed INTEGER NOT NULL,
                    suspended_failed INTEGER NOT NULL,
                    permanent_failures INTEGER NOT NULL,
                    completion_rate REAL NOT NULL,
                    runtime_hours REAL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å¤‰åŒ–ã‚¢ãƒ©ãƒ¼ãƒˆ
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS user_status_alerts (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT NOT NULL,
                    service_name TEXT NOT NULL,
                    alert_type TEXT NOT NULL,
                    severity TEXT NOT NULL,
                    title TEXT NOT NULL,
                    description TEXT,
                    metrics_json TEXT,
                    predictions_json TEXT,
                    resolved BOOLEAN DEFAULT FALSE,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å¤‰åŒ–äºˆæ¸¬ãƒ†ãƒ¼ãƒ–ãƒ«
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS status_change_predictions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT NOT NULL,
                    service_name TEXT NOT NULL,
                    prediction_type TEXT NOT NULL,
                    confidence_score REAL NOT NULL,
                    estimated_time_hours REAL,
                    predicted_change_count INTEGER,
                    factors_json TEXT,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            conn.commit()
            print(f"ğŸ‘¥ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç›£è¦–ãƒ†ãƒ¼ãƒ–ãƒ«åˆæœŸåŒ–å®Œäº†: {self.db.db_file}")
    
    def record_service_status(self, service_data: Dict[str, Any]) -> None:
        """ã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’è¨˜éŒ²"""
        current_time = time.time()
        
        with sqlite3.connect(self.db.db_file) as conn:
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT INTO user_status_history 
                (timestamp, session_id, service_name, total_users, blocked_users, 
                 failed_users, active_failed, suspended_failed, permanent_failures, 
                 completion_rate, runtime_hours)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                current_time,
                self.session_id,
                service_data['service_name'],
                service_data['total_users'],
                service_data['blocked_users'],
                service_data['failed_users'],
                service_data['active_failed'],
                service_data['suspended_failed'],
                service_data['permanent_failures'],
                service_data['completion_rate'],
                service_data.get('runtime_hours', 0)
            ))
    
    def analyze_status_changes(self, service_name: str) -> Dict[str, Any]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å¤‰åŒ–ã®åˆ†æ"""
        with sqlite3.connect(self.db.db_file) as conn:
            cursor = conn.cursor()
            
            # éå»24æ™‚é–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            cursor.execute("""
                SELECT timestamp, active_failed, suspended_failed, total_users, 
                       completion_rate, runtime_hours
                FROM user_status_history 
                WHERE service_name = ? AND timestamp > ?
                ORDER BY timestamp DESC
            """, (service_name, time.time() - 24*3600))
            
            history_data = cursor.fetchall()
            
            if len(history_data) < 2:
                return {"status": "insufficient_data", "message": "åˆ†æã«ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"}
            
            # å¤‰åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ
            analysis = {
                "service_name": service_name,
                "data_points": len(history_data),
                "time_span_hours": (history_data[0][0] - history_data[-1][0]) / 3600,
                "trends": self._analyze_trends(history_data),
                "predictions": self._predict_status_changes(history_data, service_name),
                "anomalies": self._detect_anomalies(history_data),
                "risk_assessment": {}
            }
            
            # ãƒªã‚¹ã‚¯è©•ä¾¡
            analysis["risk_assessment"] = self._assess_403_error_risk(analysis)
            
            return analysis
    
    def _analyze_trends(self, history_data: List[Tuple]) -> Dict[str, Any]:
        """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å¤‰åŒ–ãƒˆãƒ¬ãƒ³ãƒ‰ã®åˆ†æ"""
        if len(history_data) < 3:
            return {"insufficient_data": True}
        
        # ãƒ‡ãƒ¼ã‚¿ã®æ™‚ç³»åˆ—é †ã«ä¸¦ã³æ›¿ãˆï¼ˆå¤ã„é †ï¼‰
        sorted_data = sorted(history_data, key=lambda x: x[0])
        
        trends = {
            "active_failed_trend": self._calculate_trend([row[1] for row in sorted_data]),
            "suspended_trend": self._calculate_trend([row[2] for row in sorted_data]),
            "completion_rate_trend": self._calculate_trend([row[4] for row in sorted_data]),
            "overall_direction": "unknown"
        }
        
        # å…¨ä½“çš„ãªå‚¾å‘ã®åˆ¤å®š
        active_trend = trends["active_failed_trend"]["direction"]
        completion_trend = trends["completion_rate_trend"]["direction"]
        
        if active_trend == "increasing" and completion_trend == "decreasing":
            trends["overall_direction"] = "deteriorating"
        elif active_trend == "decreasing" and completion_trend == "increasing":
            trends["overall_direction"] = "improving"
        elif active_trend == "stable" and completion_trend == "stable":
            trends["overall_direction"] = "stable"
        else:
            trends["overall_direction"] = "mixed"
        
        return trends
    
    def _calculate_trend(self, values: List[float]) -> Dict[str, Any]:
        """æ•°å€¤åˆ—ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¨ˆç®—"""
        if len(values) < 2:
            return {"direction": "unknown", "change_rate": 0, "confidence": 0}
        
        # ç·šå½¢å›å¸°ã§ã®å‚¾å‘è¨ˆç®—
        n = len(values)
        x_values = list(range(n))
        
        # å‚¾ãã®è¨ˆç®—
        x_mean = sum(x_values) / n
        y_mean = sum(values) / n
        
        numerator = sum((x_values[i] - x_mean) * (values[i] - y_mean) for i in range(n))
        denominator = sum((x_values[i] - x_mean) ** 2 for i in range(n))
        
        if denominator == 0:
            slope = 0
        else:
            slope = numerator / denominator
        
        # æ–¹å‘ã®åˆ¤å®š
        if abs(slope) < 0.01:  # é–¾å€¤ä»¥ä¸‹ã¯å®‰å®š
            direction = "stable"
        elif slope > 0:
            direction = "increasing"
        else:
            direction = "decreasing"
        
        # å¤‰åŒ–ç‡ã®è¨ˆç®—
        if values[0] != 0:
            change_rate = ((values[-1] - values[0]) / values[0]) * 100
        else:
            change_rate = 0
        
        # ä¿¡é ¼åº¦ã®è¨ˆç®—ï¼ˆãƒ‡ãƒ¼ã‚¿ç‚¹æ•°ã¨å¤‰åŒ–ã®ä¸€è²«æ€§ã«åŸºã¥ãï¼‰
        confidence = min(100, (n - 1) * 20)  # æœ€å¤§100%
        
        return {
            "direction": direction,
            "change_rate": change_rate,
            "confidence": confidence,
            "slope": slope
        }
    
    def _predict_status_changes(self, history_data: List[Tuple], service_name: str) -> Dict[str, Any]:
        """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å¤‰åŒ–ã®äºˆæ¸¬"""
        if len(history_data) < 3:
            return {"prediction_available": False}
        
        sorted_data = sorted(history_data, key=lambda x: x[0])
        current_active = sorted_data[-1][1]  # æœ€æ–°ã®activeå¤±æ•—æ•°
        
        # éå»ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‹ã‚‰äºˆæ¸¬
        recent_data = sorted_data[-5:]  # ç›´è¿‘5ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ
        active_values = [row[1] for row in recent_data]
        
        trend = self._calculate_trend(active_values)
        
        predictions = {
            "prediction_available": True,
            "current_active_failed": current_active,
            "trend_direction": trend["direction"],
            "predicted_scenarios": {}
        }
        
        # ã‚·ãƒŠãƒªã‚ªåˆ¥äºˆæ¸¬
        if trend["direction"] == "increasing":
            # å¢—åŠ å‚¾å‘ã®å ´åˆ
            hourly_increase = abs(trend["slope"])
            predictions["predicted_scenarios"] = {
                "1_hour": {
                    "active_failed": current_active + hourly_increase,
                    "risk_level": "low" if hourly_increase < 10 else "medium"
                },
                "3_hours": {
                    "active_failed": current_active + hourly_increase * 3,
                    "risk_level": "medium" if hourly_increase < 10 else "high"
                },
                "6_hours": {
                    "active_failed": current_active + hourly_increase * 6,
                    "risk_level": "high" if hourly_increase > 5 else "medium"
                }
            }
        elif trend["direction"] == "stable":
            predictions["predicted_scenarios"] = {
                "1_hour": {"active_failed": current_active, "risk_level": "low"},
                "3_hours": {"active_failed": current_active, "risk_level": "low"},
                "6_hours": {"active_failed": current_active, "risk_level": "low"}
            }
        else:  # decreasing
            predictions["predicted_scenarios"] = {
                "1_hour": {"active_failed": max(0, current_active - abs(trend["slope"])), "risk_level": "low"},
                "3_hours": {"active_failed": max(0, current_active - abs(trend["slope"]) * 3), "risk_level": "low"},
                "6_hours": {"active_failed": max(0, current_active - abs(trend["slope"]) * 6), "risk_level": "low"}
            }
        
        # äºˆæ¸¬ã®ä¿å­˜
        self._save_predictions(service_name, predictions)
        
        return predictions
    
    def _save_predictions(self, service_name: str, predictions: Dict[str, Any]) -> None:
        """äºˆæ¸¬çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
        if not predictions.get("prediction_available"):
            return
        
        with sqlite3.connect(self.db.db_file) as conn:
            cursor = conn.cursor()
            
            for time_horizon, scenario in predictions["predicted_scenarios"].items():
                confidence = 0.8 if predictions["trend_direction"] == "stable" else 0.6
                
                cursor.execute("""
                    INSERT INTO status_change_predictions 
                    (session_id, service_name, prediction_type, confidence_score,
                     estimated_time_hours, predicted_change_count, factors_json)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                """, (
                    self.session_id,
                    service_name,
                    f"active_failed_{time_horizon}",
                    confidence,
                    int(time_horizon.split('_')[0]),
                    scenario["active_failed"],
                    json.dumps({"trend": predictions["trend_direction"], "risk": scenario["risk_level"]})
                ))
    
    def _detect_anomalies(self, history_data: List[Tuple]) -> List[Dict[str, Any]]:
        """ç•°å¸¸å€¤ã®æ¤œå‡º"""
        anomalies = []
        
        if len(history_data) < 5:
            return anomalies
        
        sorted_data = sorted(history_data, key=lambda x: x[0])
        
        # activeå¤±æ•—æ•°ã®ç•°å¸¸å€¤æ¤œå‡º
        active_values = [row[1] for row in sorted_data]
        avg_active = sum(active_values) / len(active_values)
        std_active = (sum((x - avg_active) ** 2 for x in active_values) / len(active_values)) ** 0.5
        
        for i, row in enumerate(sorted_data):
            active_failed = row[1]
            if abs(active_failed - avg_active) > 2 * std_active:  # 2Ïƒä»¥ä¸Šã®åå·®
                anomalies.append({
                    "type": "active_failed_spike",
                    "timestamp": row[0],
                    "value": active_failed,
                    "expected_range": f"{avg_active - 2*std_active:.0f} - {avg_active + 2*std_active:.0f}",
                    "severity": "high" if abs(active_failed - avg_active) > 3 * std_active else "medium"
                })
        
        # å®Œäº†ç‡ã®æ€¥æ¿€ãªå¤‰åŒ–
        completion_rates = [row[4] for row in sorted_data]
        for i in range(1, len(completion_rates)):
            rate_change = abs(completion_rates[i] - completion_rates[i-1])
            if rate_change > 0.1:  # 10%ä»¥ä¸Šã®æ€¥æ¿€ãªå¤‰åŒ–
                anomalies.append({
                    "type": "completion_rate_jump",
                    "timestamp": sorted_data[i][0],
                    "value": completion_rates[i],
                    "change": rate_change,
                    "severity": "high" if rate_change > 0.2 else "medium"
                })
        
        return anomalies
    
    def _assess_403_error_risk(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """403ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿãƒªã‚¹ã‚¯ã®è©•ä¾¡"""
        risk_factors = []
        risk_score = 0
        
        trends = analysis.get("trends", {})
        predictions = analysis.get("predictions", {})
        anomalies = analysis.get("anomalies", [])
        
        # activeå¤±æ•—æ•°ã®å¢—åŠ ãƒˆãƒ¬ãƒ³ãƒ‰
        if trends.get("active_failed_trend", {}).get("direction") == "increasing":
            risk_factors.append("Activeå¤±æ•—æ•°ã®å¢—åŠ å‚¾å‘")
            risk_score += 30
        
        # å®Œäº†ç‡ã®ä½ä¸‹
        if trends.get("completion_rate_trend", {}).get("direction") == "decreasing":
            risk_factors.append("å®Œäº†ç‡ã®ä½ä¸‹å‚¾å‘")
            risk_score += 25
        
        # é«˜ãƒªã‚¹ã‚¯äºˆæ¸¬ã‚·ãƒŠãƒªã‚ª
        if predictions.get("prediction_available"):
            for scenario in predictions.get("predicted_scenarios", {}).values():
                if scenario.get("risk_level") == "high":
                    risk_factors.append("é«˜ãƒªã‚¹ã‚¯äºˆæ¸¬ã‚·ãƒŠãƒªã‚ªã®å­˜åœ¨")
                    risk_score += 20
                    break
        
        # ç•°å¸¸å€¤ã®å­˜åœ¨
        high_severity_anomalies = [a for a in anomalies if a.get("severity") == "high"]
        if high_severity_anomalies:
            risk_factors.append(f"é«˜é‡è¦åº¦ç•°å¸¸å€¤ ({len(high_severity_anomalies)}ä»¶)")
            risk_score += len(high_severity_anomalies) * 15
        
        # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã®åˆ¤å®š
        if risk_score >= 70:
            risk_level = "CRITICAL"
        elif risk_score >= 50:
            risk_level = "HIGH"
        elif risk_score >= 30:
            risk_level = "MEDIUM"
        else:
            risk_level = "LOW"
        
        return {
            "risk_level": risk_level,
            "risk_score": min(100, risk_score),
            "risk_factors": risk_factors,
            "recommendations": self._generate_risk_recommendations(risk_level, risk_factors)
        }
    
    def _generate_risk_recommendations(self, risk_level: str, risk_factors: List[str]) -> List[str]:
        """ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã«åŸºã¥ãæ¨å¥¨äº‹é …ã®ç”Ÿæˆ"""
        recommendations = []
        
        if risk_level == "CRITICAL":
            recommendations.extend([
                "ğŸš¨ ç·Šæ€¥å¯¾å¿œ: ã‚·ã‚¹ãƒ†ãƒ åœæ­¢ã‚’æ¤œè¨",
                "ğŸ” è©³ç´°èª¿æŸ»: activeå¤±æ•—ã®æ€¥å¢—åŸå› ã‚’ç‰¹å®š",
                "ğŸ› ï¸ å³åº§ä¿®æ­£: Cookieå†èª­ã¿è¾¼ã¿ãƒ»ãƒ˜ãƒƒãƒ€ãƒ¼å¤‰æ›´",
                "ğŸ“Š ç›£è¦–å¼·åŒ–: 1æ™‚é–“ä»¥å†…ã®å†ãƒã‚§ãƒƒã‚¯"
            ])
        elif risk_level == "HIGH":
            recommendations.extend([
                "âš ï¸ äºˆé˜²çš„å¯¾å¿œ: å‡¦ç†é€Ÿåº¦ã®èª¿æ•´",
                "ğŸ”„ ã‚·ã‚¹ãƒ†ãƒ èª¿æ•´: ãƒãƒƒã‚¯ã‚ªãƒ•æ™‚é–“ã®å»¶é•·",
                "ğŸ“ˆ ç›£è¦–é »åº¦: 2æ™‚é–“ä»¥å†…ã®å†ãƒã‚§ãƒƒã‚¯",
                "ğŸ›¡ï¸ å¯¾ç­–æº–å‚™: ç·Šæ€¥åœæ­¢æ‰‹é †ã®ç¢ºèª"
            ])
        elif risk_level == "MEDIUM":
            recommendations.extend([
                "ğŸ“Š ç¶™ç¶šç›£è¦–: ãƒˆãƒ¬ãƒ³ãƒ‰ã®æ³¨æ„æ·±ã„è¦³å¯Ÿ",
                "ğŸ”§ äºˆé˜²ä¿å®ˆ: ã‚·ã‚¹ãƒ†ãƒ è¨­å®šã®æœ€é©åŒ–",
                "ğŸ“… å®šæœŸãƒã‚§ãƒƒã‚¯: 4-6æ™‚é–“å¾Œã®å†ç¢ºèª"
            ])
        else:  # LOW
            recommendations.extend([
                "âœ… ç¾çŠ¶ç¶­æŒ: å®‰å®šã—ãŸçŠ¶æ…‹ã‚’ç¶™ç¶š",
                "ğŸ“‹ å®šæœŸç›£è¦–: é€šå¸¸ã®ç›£è¦–ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«"
            ])
        
        # ç‰¹å®šã®ãƒªã‚¹ã‚¯è¦å› ã«å¯¾ã™ã‚‹æ¨å¥¨äº‹é …
        for factor in risk_factors:
            if "Activeå¤±æ•—æ•°ã®å¢—åŠ " in factor:
                recommendations.append("ğŸ” Activeå¤±æ•—ã®è©³ç´°åˆ†æ: ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—ã®åˆ†é¡ç¢ºèª")
            if "å®Œäº†ç‡ã®ä½ä¸‹" in factor:
                recommendations.append("ğŸ“ˆ å‡¦ç†åŠ¹ç‡ã®æ”¹å–„: ãƒãƒƒãƒã‚µã‚¤ã‚ºãƒ»é…å»¶ã®èª¿æ•´")
            if "é«˜é‡è¦åº¦ç•°å¸¸å€¤" in factor:
                recommendations.append("ğŸ•µï¸ ç•°å¸¸å€¤èª¿æŸ»: ç‰¹å®šæ™‚é–“å¸¯ã®è©³ç´°ãƒ­ã‚°ç¢ºèª")
        
        return recommendations
    
    def create_status_alert(self, service_name: str, alert_type: str, severity: str,
                           title: str, description: str = "",
                           metrics: Dict = None, predictions: Dict = None) -> None:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å¤‰åŒ–ã‚¢ãƒ©ãƒ¼ãƒˆã®ç”Ÿæˆ"""
        with sqlite3.connect(self.db.db_file) as conn:
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT INTO user_status_alerts 
                (session_id, service_name, alert_type, severity, title, 
                 description, metrics_json, predictions_json)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                self.session_id,
                service_name,
                alert_type,
                severity,
                title,
                description,
                json.dumps(metrics or {}),
                json.dumps(predictions or {})
            ))
    
    def get_monitoring_summary(self) -> Dict[str, Any]:
        """ç›£è¦–çŠ¶æ³ã®æ¦‚è¦å–å¾—"""
        with sqlite3.connect(self.db.db_file) as conn:
            cursor = conn.cursor()
            
            # ã‚µãƒ¼ãƒ“ã‚¹åˆ¥ã®æœ€æ–°çŠ¶æ³
            cursor.execute("""
                SELECT service_name, active_failed, completion_rate, 
                       MAX(timestamp) as latest_timestamp
                FROM user_status_history 
                WHERE session_id = ?
                GROUP BY service_name
            """, (self.session_id,))
            
            services_status = cursor.fetchall()
            
            # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆæ•°
            cursor.execute("""
                SELECT COUNT(*) as total_alerts,
                       COUNT(CASE WHEN severity = 'CRITICAL' THEN 1 END) as critical_alerts,
                       COUNT(CASE WHEN severity = 'HIGH' THEN 1 END) as high_alerts
                FROM user_status_alerts 
                WHERE session_id = ? AND resolved = FALSE
            """, (self.session_id,))
            
            alert_counts = cursor.fetchone()
        
        summary = {
            "session_id": self.session_id,
            "monitoring_active": True,
            "services_monitored": len(services_status),
            "services_status": [
                {
                    "service_name": row[0],
                    "active_failed": row[1],
                    "completion_rate": row[2],
                    "last_updated": datetime.fromtimestamp(row[3]).isoformat()
                }
                for row in services_status
            ],
            "alerts": {
                "total": alert_counts[0] if alert_counts else 0,
                "critical": alert_counts[1] if alert_counts else 0,
                "high": alert_counts[2] if alert_counts else 0
            }
        }
        
        return summary